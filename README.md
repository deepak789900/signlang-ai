# ğŸ¤Ÿ Sign Language Recognition System

This is a Python-based web application that recognizes hand gestures representing sign language using a deep learning model. It is designed to help bridge the communication gap between hearing-impaired individuals and the wider community by translating sign language into readable text in real time.

---

## ğŸ“– About the Project

The Sign Language Recognition System is built using deep learning and computer vision. The project uses a pre-trained neural network to classify images of hand gestures captured through a webcam and displays the recognized sign as readable text on a user-friendly web interface. This system can be further extended to support different sign languages (e.g., ASL, BSL) and speech synthesis.

---

## ğŸ¯ Objective

- To develop a system that can accurately detect and interpret sign language gestures.
- To provide a real-time translation of hand gestures into text.
- To support inclusive communication through technology.
- To demonstrate the integration of AI models with web applications.

---

## ğŸ’» Technologies Used

### ğŸ‘¨â€ğŸ’» Backend
- **Python 3**
- **Flask** â€“ for the web application
- **TensorFlow / Keras** â€“ for deep learning model
- **OpenCV** â€“ for image capture and processing
- **SQLite** â€“ for local database storage

### ğŸ¨ Frontend
- **HTML / CSS**
- **JavaScript**
- **Bootstrap** â€“ for responsive UI

### ğŸ§  Model & Tools
- **Convolutional Neural Networks (CNNs)**
- **Keras Pre-trained Model (`keras_model.h5`)**
- **Speech Synthesis (Text-to-Speech)** using `pyttsx3` or similar

---

## ğŸš€ Features

- Real-time gesture capture via webcam
- Gesture-to-text translation using trained model
- Text-to-speech support
- Secure login and user registration
- Feedback and form submission pages
- Responsive and interactive UI

---


