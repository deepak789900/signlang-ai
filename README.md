# 🤟 Sign Language Recognition System

This is a Python-based web application that recognizes hand gestures representing sign language using a deep learning model. It is designed to help bridge the communication gap between hearing-impaired individuals and the wider community by translating sign language into readable text in real time.

---

## 📖 About the Project

The Sign Language Recognition System is built using deep learning and computer vision. The project uses a pre-trained neural network to classify images of hand gestures captured through a webcam and displays the recognized sign as readable text on a user-friendly web interface. This system can be further extended to support different sign languages (e.g., ASL, BSL) and speech synthesis.

---

## 🎯 Objective

- To develop a system that can accurately detect and interpret sign language gestures.
- To provide a real-time translation of hand gestures into text.
- To support inclusive communication through technology.
- To demonstrate the integration of AI models with web applications.

---

## 💻 Technologies Used

### 👨‍💻 Backend
- **Python 3**
- **Flask** – for the web application
- **TensorFlow / Keras** – for deep learning model
- **OpenCV** – for image capture and processing
- **SQLite** – for local database storage

### 🎨 Frontend
- **HTML / CSS**
- **JavaScript**
- **Bootstrap** – for responsive UI

### 🧠 Model & Tools
- **Convolutional Neural Networks (CNNs)**
- **Keras Pre-trained Model (`keras_model.h5`)**
- **Speech Synthesis (Text-to-Speech)** using `pyttsx3` or similar

---

## 🚀 Features

- Real-time gesture capture via webcam
- Gesture-to-text translation using trained model
- Text-to-speech support
- Secure login and user registration
- Feedback and form submission pages
- Responsive and interactive UI

---


